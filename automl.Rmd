---
title: Democratising Policy Analytics with AutoML
author: Danilo Freire[^info]
date: \today
abstract: ""
fontsize: 12pt
bibliography: references.bib
biblio-style: apalike
output:
   pdf_document:
     number_sections: true
header-includes:
   - \usepackage[UKenglish]{babel}
   - \usepackage[UKenglish]{isodate}
   - \usepackage{libertine}
   - \usepackage[libertine]{newtxmath}
   - \usepackage{inconsolata}
   - \usepackage{setspace}
---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# If you need to install any package while knitting the document
r <- getOption("repos")
r["CRAN"] <- "https://cran.rstudio.com/"
options(repos = r)

if (!require("kableExtra")) {
    install.packages("kableExtra")
}
if (!require("reticulate")) {
    install.packages("reticulate")
}

def_chunk_hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def_chunk_hook(x, options)
  ifelse(options$size != "normalsize",
         paste0("\n \\", options$size, "\n\n", x,
                "\n\n \\normalsize"), x)
})
```

[^info]: Independent researcher,
[danilofreire@gmail.com](mailto:danilofreire@gmail.com),
<https://danilofreire.github.io>.

\doublespacing

# Introduction

Machine learning has made steady inroads into the social sciences. Although
causal inference designs are now the standard methodology in economics and
political science [@angrist2008mostly], machine learning models are
increasingly used to tackle "prediction policy problems", in which high
forecasting accuracy is more important that unbiased regression coefficients
[@kleinberg2015prediction]. For instance, scholars have employed algorithmic
modelling to predict civil wars [@muchlinski2016comparing; @ward2010perils],
mass killings [@freire2018drives; @ulfelder2013multimodel], and state
repression [@hill2014empirical]. Supervised machine learning also helps
governments to devise local public policies, such as allocating fire inspection
teams or directing patients for medical treatment [@athey2017beyond].
Therefore, computer algorithms can improve social welfare by making state
interventions more effective and personalised.

Despite the popularity of predictive analytics, building machine learning
models remains a labour-intensive task. Practitioners often apply several
preprocessing steps just to make their data suitable for analysis, and
modelling decisions such as algorithm selection and parameter optimisation are
still largely based on trial and error [@elshawi2019automated]. As a result,
many areas that could benefit from predictive algorithms do not reach their
full potential due to implementation challenges or lack of technical expertise
[@amershi2019software; @truong2019towards; @yang2018grounding]. In this regard,
methods that simplify the machine learning pipeline can have significant
academic and policy impacts [@ahmed2020framework; @healy2017bridging].

Automated machine learning (AutoML) aims to fill this gap. AutoML is an
emerging framework that automatically chooses and optimises machine learning
algorithms. More specifically, AutoML provides data-driven tools to minimise
human effort in the machine learning workflow, automating steps like feature
engineering, model selection, hyperparameter tuning, and model interpretation
[@elshawi2019automated]. AutoML not only frees machine learning specialists
from tedious and error-prone tasks, but also makes state-of-the-art algorithms
accessible to regular users. According to their proponents, AutoML promotes a
true democratisation of artificial intelligence [@hutter2019automated, ix;
@shang2019democratizing]. AutoML approaches have also been very successful in
prediction challenges, and they consistently reach the top 5% in public machine
learning competitions [@autogluon2020kaggle; @googleblog2020automl].

In this paper, I introduce four Python AutoML algorithms that policy analysts
may consider in their work. In the first section, I describe the main
functionalities of `AutoGluon` [@erickson2020autogluon], `Auto-sklearn`
[@feurer2015efficient], `H2O AutoML` [@ledell2020h2o], and `TPOT`
[@olson2016tpot]. All of the algorithms are open source, actively maintained,
and easy to use, thus suitable for both academic and business environments. In
the third section, I replicate two articles that employ expert-coded machine
learning models and show that AutoML can achieve comparable or better predictive
performance with only a few lines of code. Lastly, I discuss how users can make
their AutoML scalable and reproducible with Docker containers. Docker allows
researchers to create an image of their complete working environment, thus all
AutoML specifications and dependencies are automatically embedded in the Docker
file. While Docker has been widely employed in business applications, its use in
academia remains limited. I provide a simple tutorial so that readers can upload
their AutoML setups to a website and share their Docker containers with
co-authors and referees.

# A Brief Introduction to AutoML Algorithms

Automated algorithms are a recent addition to the machine learning field.
@thornton2013auto proposed the first method to jointly address the problems of
algorithm selection and parameter optimisation, and their results showed that
automated solutions often outperformed baseline methods. Since then, the
literature has grown significantly. Today, there is today a multitude of AutoML
algorithms available for non-expert users, which are not only able to predict
numeric data, but also to classify objects, translate text, annotate videos,
and perform sentiment analysis in social media [@liu2020far].

The intuition behind AutoML algorithms is quite simple. First, the algorithm
splits the data into training and testing sets and applies different models to
them in each iteration. Then, the algorithm selects the model which achieves
the best performance in a given evaluation metric, such as the mean squared
error or classification accuracy. AutoML can find the most suitable machine
learning method by testing every model separately or by combining a diverse set
of models and applying optimisation techniques to speed up the process. The
next step is to find the best set of model hyperparameters to further improve
the predictive ability of the chosen method. The process here is similar to the
previous one. The algorithm tests many combinations of parameters and selects
the one which gives the best results in the original metric. There are several
ways to achieve these goals, and the literature is rapidly evolving, but these
are the main principles that guide every AutoML algorithm.

Most AutoML libraries also perform feature engineering tasks without human
intervention. Feature engineering is the process of recoding variables to
improve the performance of machine learning algorithms. Common tasks include
creating dummy variables from categorical indicators, filling missing data,
standardising numeric covariates, or removing features that are strongly
correlated to avoid multicollinearity [@he2020automl; @truong2019towards].
AutoML takes a data-driven approach here too, and selects those data
transformations that contribute the most to improving forecasting scores.

## AutoGluon

`AutoGluon` is an automated machine learning framework developed by Amazon Web
Service Labs. It allows users to ensemble multiple models and stack them into
many layers, which often increases forecasting accuracy. `AutoGluon` is under
active development and its code is available at
<https://github.com/awslabs/autogluon>. The Python library is also easy to
install and deploy, and researchers can create powerful deep learning or
tree-based models with just three lines of code [@erickson2020autogluon, 1].
Indeed, non-experts only need to know three functions to get started with the
library, namely `Dataset()`, `fit()`, and `predict()`. The basic model pipeline
looks like this:

\vspace{.3cm}

```{python, eval = FALSE, size="footnotesize"}
pip install autogluon                                      # install library
import autogluon as ag                                     # load library
from autogluon import TabularPrediction as task            # import module

data = task.Dataset("path/to/dataset")                     # load data
model = task.fit(data_train, label=dependent_variable)     # fit model
predictions = model.predict(new_data)                      # predict
```

Experienced machine learning practitioners may also adapt the `fit()` function
to their needs and choose amongst different learners and change hyperparameter
settings. However, the default configurations probably suit most users.
Moreover, `AutoGluon` can distribute the calculations across multiple computers,
which is handy if you have access to Google Cloud or Amazon EC2.

## Auto-sklearn

`Auto-sklearn` is an AutoML library built on top of `scikit-learn` [@scikit],
one of the most popular machine learning modules for Python. Developed by a
research team from the University of Freiburg and the University of Hannover,
`Auto-sklearn` uses a meta-learning method that compares similar datasets and
identify which algorithm is most adequate for that particular prediction tests.
According to the authors, this procedure improves the library performance and
speeds up processing times.[^metalearner] `Auto-sklearn` has proved successful
in machine learning competitions, too. In 2016, the algorithm won six out of ten
tracks of the ChaLearn Automatic Machine Learning Challenge[^chalearn], that
evaluated the accuracy of AutoML models estimated without any human
intervention. It is straightforward for users to get started with
`Auto-sklearn`. For instance, the code below runs an automated classification
model:

[^metalearner]: For more details, see
<https://www.automl.org/automl/auto-sklearn/>.

[^chalearn]: The results are available at <https://competitions.codalab.org/competitions/2321>.

\vspace{.3cm}

```{python, eval = FALSE, size="footnotesize"}
pip install autosklearn                                    # install library
import autosklearn.classification                          # load library

model = autosklearn.classification.AutoSklearnClassifier() # load model
model.fit(X_training_data, y_training_data)                # estimate model
predictions = model.predict(X_test_data)                   # create predictions
```

In the example, $X$ is a matrix of covariates and $y$ is a binary dependent
variable. As it is common practice in the machine learning literature, the
original dataset should be split into two parts, namely _training_ and _test_
data. The training dataset consists of the observations the algorithm will use
to estimate the model, which will later be evaluated using the test data
partition. Researchers often include a _validation_ dataset between the two
other splits to tune model hyperparameters.

In comparison with `AutoGluon`, `Auto-sklearn` has the advantage of offering 15
algorithms, 10 more than the former, and the new `Auto-sklearn` 2.0 also
provides good results even under small estimation times. If practitioners need
to quickly run a model, they can achieve a low error rate under 10 minutes
[@askl2, 11]. Nonetheless, `Auto-sklearn` only accepts numeric data as inputs,
so in case one would like to analyse images or text, they could only do so using
`AutoGluon`.

## H2O AutoML

The third algorithm I discuss here is `H2O AutoML`. The software is a recent
product by H2O.ai, a company based in Silicon Valley which has developed several
machine learning solutions. `H2O AutoML` is free and open source, so firms and
individuals can use it at no cost, and they can inspect and modify the
original code if they want to. Another advantage of `H2O AutoML` is that it
provides a graphic user interface to help novices to get started with the
platform. The company offers a version of their AutoML software for `R` and
`Python`, and the two packages use the same arguments, which makes it easy for
users who use both languages in their work. Users only need to specify the
dependent and independent variables, and the training and validation datasets.
You may find a code example for binary classification problems below:

\vspace{.3cm}

```{python, eval = FALSE, size="footnotesize"}
pip install h2o                                  # install library
import h2o                                       # load library
from h2o.automl import H2OAutoML                 # load AutoML functions
h2o.init()                                       # start the module

train = h2o.import_file("path/to/training_data") # load training data
test = h2o.import_file("path/to/test_data")      # load test data

x = train.columns                                # independent variables
y = "dependent_variable_name"                    # dependent variable
x.remove(y)                                      # remove dependent variable from matrix

model = H2OAutoML(max_models=30, seed=1234)      # run 30 machine learning models
model.train(x=x, y=y, training_frame=train)      # estimate model
predictions = model.predict(test)                # get predictions
```

One feature that sets `H2O AutoML` apart from the other packages shown here is
its large collection of model explainability functions. Critics have pointed out
that most machine learning methods are "black boxes", in the sense that they
display little information about how the estimation is made
[@molnar2020interpretable]. This has serious consequences in fields where
decision mechanisms are relevant per se, like judicial sentences or health care
allocation. `H2O AutoML` addresses this issue by offering explanation functions
that shows how the model perform as a whole and how it explains each individual
observation.[^explain] The algorithm also shows the importance of every
predictor [@gromping2009variable], SHAP values [@lundberg2020local], and partial
dependence plots [@friedman2003multiple].

[^explain]: Please visit
<http://docs.h2o.ai/h2o/latest-stable/h2o-docs/explain.html> for more
information on `H2O AutoML`'s model explainability functions.

## TPOT

The last algorithm presented in this section is `TPOT`, or _Tree-based Pipeline
Optimization Tool_. It is one of oldest AutoML solutions for Python, and its
authors have won several awards for their work on the algorithm.[^tpot-awards] 

[^tpot-awards]: A list of the awards is available at <http://automl.info/tpot/>.












\newpage

# References
